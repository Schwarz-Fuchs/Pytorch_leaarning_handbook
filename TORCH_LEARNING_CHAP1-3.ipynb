{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CHAPTER 1 GET YOUR TORCH READY",
   "id": "8098e4c5455a72eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:17.748602Z",
     "start_time": "2025-09-09T09:34:17.051775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from sklearn.externals.array_api_compat.torch import equal\n",
    "from torch import dtype\n",
    "from torch.onnx.symbolic_opset11 import chunk\n",
    "\n",
    "# 1.torch installation test\n",
    "print(torch.__version__) #输出版本\n",
    "print(torch.cuda.is_available()) #输出是否使用cuda\n",
    "print(torch.version.cuda) #输出CUDA版本\n",
    "print(torch.cuda.get_device_name()) #输出torch使用的GPU设备\n",
    "\n",
    "# deep learning with Pytorch 建议使用1070以上 8G显存的卡"
   ],
   "id": "1cd7d105b27ddd48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu129\n",
      "True\n",
      "12.9\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CHAPTER 2 RUN SOME PRETRAINED MODELS",
   "id": "23e6e17e6bc84a24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:17.779499Z",
     "start_time": "2025-09-09T09:34:17.758569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "#models built in\n",
    "dir(models)"
   ],
   "id": "e3449381a8228552",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'AlexNet_Weights',\n",
       " 'ConvNeXt',\n",
       " 'ConvNeXt_Base_Weights',\n",
       " 'ConvNeXt_Large_Weights',\n",
       " 'ConvNeXt_Small_Weights',\n",
       " 'ConvNeXt_Tiny_Weights',\n",
       " 'DenseNet',\n",
       " 'DenseNet121_Weights',\n",
       " 'DenseNet161_Weights',\n",
       " 'DenseNet169_Weights',\n",
       " 'DenseNet201_Weights',\n",
       " 'EfficientNet',\n",
       " 'EfficientNet_B0_Weights',\n",
       " 'EfficientNet_B1_Weights',\n",
       " 'EfficientNet_B2_Weights',\n",
       " 'EfficientNet_B3_Weights',\n",
       " 'EfficientNet_B4_Weights',\n",
       " 'EfficientNet_B5_Weights',\n",
       " 'EfficientNet_B6_Weights',\n",
       " 'EfficientNet_B7_Weights',\n",
       " 'EfficientNet_V2_L_Weights',\n",
       " 'EfficientNet_V2_M_Weights',\n",
       " 'EfficientNet_V2_S_Weights',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'GoogLeNet_Weights',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'Inception_V3_Weights',\n",
       " 'MNASNet',\n",
       " 'MNASNet0_5_Weights',\n",
       " 'MNASNet0_75_Weights',\n",
       " 'MNASNet1_0_Weights',\n",
       " 'MNASNet1_3_Weights',\n",
       " 'MaxVit',\n",
       " 'MaxVit_T_Weights',\n",
       " 'MobileNetV2',\n",
       " 'MobileNetV3',\n",
       " 'MobileNet_V2_Weights',\n",
       " 'MobileNet_V3_Large_Weights',\n",
       " 'MobileNet_V3_Small_Weights',\n",
       " 'RegNet',\n",
       " 'RegNet_X_16GF_Weights',\n",
       " 'RegNet_X_1_6GF_Weights',\n",
       " 'RegNet_X_32GF_Weights',\n",
       " 'RegNet_X_3_2GF_Weights',\n",
       " 'RegNet_X_400MF_Weights',\n",
       " 'RegNet_X_800MF_Weights',\n",
       " 'RegNet_X_8GF_Weights',\n",
       " 'RegNet_Y_128GF_Weights',\n",
       " 'RegNet_Y_16GF_Weights',\n",
       " 'RegNet_Y_1_6GF_Weights',\n",
       " 'RegNet_Y_32GF_Weights',\n",
       " 'RegNet_Y_3_2GF_Weights',\n",
       " 'RegNet_Y_400MF_Weights',\n",
       " 'RegNet_Y_800MF_Weights',\n",
       " 'RegNet_Y_8GF_Weights',\n",
       " 'ResNeXt101_32X8D_Weights',\n",
       " 'ResNeXt101_64X4D_Weights',\n",
       " 'ResNeXt50_32X4D_Weights',\n",
       " 'ResNet',\n",
       " 'ResNet101_Weights',\n",
       " 'ResNet152_Weights',\n",
       " 'ResNet18_Weights',\n",
       " 'ResNet34_Weights',\n",
       " 'ResNet50_Weights',\n",
       " 'ShuffleNetV2',\n",
       " 'ShuffleNet_V2_X0_5_Weights',\n",
       " 'ShuffleNet_V2_X1_0_Weights',\n",
       " 'ShuffleNet_V2_X1_5_Weights',\n",
       " 'ShuffleNet_V2_X2_0_Weights',\n",
       " 'SqueezeNet',\n",
       " 'SqueezeNet1_0_Weights',\n",
       " 'SqueezeNet1_1_Weights',\n",
       " 'SwinTransformer',\n",
       " 'Swin_B_Weights',\n",
       " 'Swin_S_Weights',\n",
       " 'Swin_T_Weights',\n",
       " 'Swin_V2_B_Weights',\n",
       " 'Swin_V2_S_Weights',\n",
       " 'Swin_V2_T_Weights',\n",
       " 'VGG',\n",
       " 'VGG11_BN_Weights',\n",
       " 'VGG11_Weights',\n",
       " 'VGG13_BN_Weights',\n",
       " 'VGG13_Weights',\n",
       " 'VGG16_BN_Weights',\n",
       " 'VGG16_Weights',\n",
       " 'VGG19_BN_Weights',\n",
       " 'VGG19_Weights',\n",
       " 'ViT_B_16_Weights',\n",
       " 'ViT_B_32_Weights',\n",
       " 'ViT_H_14_Weights',\n",
       " 'ViT_L_16_Weights',\n",
       " 'ViT_L_32_Weights',\n",
       " 'VisionTransformer',\n",
       " 'Weights',\n",
       " 'WeightsEnum',\n",
       " 'Wide_ResNet101_2_Weights',\n",
       " 'Wide_ResNet50_2_Weights',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_api',\n",
       " '_meta',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'convnext',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'efficientnet',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_v2_l',\n",
       " 'efficientnet_v2_m',\n",
       " 'efficientnet_v2_s',\n",
       " 'get_model',\n",
       " 'get_model_builder',\n",
       " 'get_model_weights',\n",
       " 'get_weight',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'list_models',\n",
       " 'maxvit',\n",
       " 'maxvit_t',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'mobilenetv2',\n",
       " 'mobilenetv3',\n",
       " 'optical_flow',\n",
       " 'quantization',\n",
       " 'regnet',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'swin_b',\n",
       " 'swin_s',\n",
       " 'swin_t',\n",
       " 'swin_transformer',\n",
       " 'swin_v2_b',\n",
       " 'swin_v2_s',\n",
       " 'swin_v2_t',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'vision_transformer',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_h_14',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.265148Z",
     "start_time": "2025-09-09T09:34:17.789466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "############### use resnet to recognize pics\n",
    "resnet=models.resnet101(pretrained=True)\n",
    "print(resnet)"
   ],
   "id": "b51e10ea75e65269",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wolff\\.conda\\envs\\PYTHON3.10_TORCH2.8\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\wolff\\.conda\\envs\\PYTHON3.10_TORCH2.8\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.561329Z",
     "start_time": "2025-09-09T09:34:18.270128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use transform to make your data input into usable form for the model\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "preprocess=transforms.Compose([\n",
    "    transforms.Resize(256), #对图片缩放 256*256\n",
    "    transforms.CenterCrop(224), #裁切取用中心 224*224\n",
    "    transforms.ToTensor(), #图片转为张量 RGB\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) #RGB网络的初始张量均值和标准差\n",
    "])\n",
    "\n",
    "test_image=Image.open(\"./images/border_collie.jpg\")\n",
    "test_image.show()\n",
    "input=preprocess(test_image)\n",
    "print(input.shape)\n",
    "\n",
    "batch_t = torch.unsqueeze(input, 0)\n",
    "\n",
    "resnet.eval() ##启用evaluate 模式\n",
    "\n",
    "out = resnet(batch_t)\n",
    "#print(out) #good! you got a possibility result for each class as a tensor\n",
    "\n",
    "with open('text_files/imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(torch.max(out,1))\n",
    "ori_value, index = torch.max(out, 1) #取用结果中可能性最大的一个结果\n",
    "#print(ori_value)\n",
    "#print(index)  #这两个东西都是一个tensor(像list一样，取值请加[0])\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100  #将输出层做softmax变换可得到可能性阵\n",
    "print(labels[index[0]], percentage[index[0]].item())  #最佳预测\n",
    "\n",
    "_, indices = torch.sort(out, descending=True)\n",
    "print([(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]) #前五名最佳预测"
   ],
   "id": "26f137e2c53dda94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.return_types.max(\n",
      "values=tensor([17.8954], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([232]))\n",
      "Border collie 75.03390502929688\n",
      "[('Border collie', 75.03390502929688), ('collie', 24.824813842773438), ('kelpie', 0.04702140390872955), ('Shetland sheepdog, Shetland sheep dog, Shetland', 0.025132307782769203), ('Cardigan, Cardigan Welsh corgi', 0.020679719746112823)]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CHAPTER3 TENSORS",
   "id": "8984a14a0ec12978"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.576275Z",
     "start_time": "2025-09-09T09:34:18.569299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#############\n",
    "#create tensor from ones or zeros\n",
    "a=torch.ones(3)\n",
    "print(a)\n",
    "print(a[2])\n",
    "print(float(a[2]))\n",
    "a[2]=3.0\n",
    "print(a)\n",
    "\n",
    "b=torch.zeros(3,2)\n",
    "print(b)\n",
    "#there are two ways to call the index of a tensor\n",
    "b[0][1]=1.0\n",
    "b[1,1]=3.0\n",
    "print(b)\n"
   ],
   "id": "d8c0a42f2e2ee675",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor(1.)\n",
      "1.0\n",
      "tensor([1., 1., 3.])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0., 1.],\n",
      "        [0., 3.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.591229Z",
     "start_time": "2025-09-09T09:34:18.582255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#the way to call the index is  just like using a Python list\n",
    "print(b[2,1])\n",
    "print(b[2][1])\n",
    "print(b[1:,:])\n",
    "print(b[:2,:1])\n",
    "print(b[None]) ##add a dimension of size 1"
   ],
   "id": "b2c06b89e5b5e43f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor([[0., 3.],\n",
      "        [0., 0.]])\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "tensor([[[0., 1.],\n",
      "         [0., 3.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.606176Z",
     "start_time": "2025-09-09T09:34:18.598201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create tensor from list-like objects\n",
    "locs=torch.tensor([[1.0,2.0],[3.0,4.0],[5.0,1.0],[2.0,3.0]])\n",
    "print(locs)\n",
    "print(locs.shape)"
   ],
   "id": "789b2be6bfdef55a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 1.],\n",
      "        [2., 3.]])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.636589Z",
     "start_time": "2025-09-09T09:34:18.614152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#tensor broadcast\n",
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "batched_img_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]\n",
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batched_img_t.mean(-3)\n",
    "print(img_gray_naive.shape, batch_gray_naive.shape)\n",
    "\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1) #expand the ori-weight tensor into a 3,1,1 tensor\n",
    "print(unsqueezed_weights.shape)\n",
    "print(unsqueezed_weights)\n",
    "\"\"\"\n",
    "广播的核心规则\n",
    "广播遵循从 最后一维向前比较 的规则，逐维度检查是否满足以下条件之一：\n",
    "1.维度大小相等，或\n",
    "2.其中一个维度大小为 1（可扩展），或\n",
    "3.其中一个张量在该维度不存在（默认为1）\n",
    "\n",
    "复制时从左向右，按照该tensor(此处可以理解为list)index下的格式，复制后扩增维目标维度\n",
    "\"\"\"\n",
    "img_weights = (img_t * unsqueezed_weights)   #注意！这里在做乘法的时候激活了广播机制，相当于原本的unsqueezed_weight被扩展成了3*5*5,而而这三个5*5矩阵分别是原始weight*I的矩阵\n",
    "batched_img_weight = (batched_img_t * unsqueezed_weights) #这里与上面类似，被广播成了2，3,5,5\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batched_img_weight.sum(-3)\n",
    "\n",
    "print(img_weights.shape, batched_img_weight.shape)\n",
    "print(img_gray_weighted.shape, batch_gray_weighted.shape)"
   ],
   "id": "67cffb2958ac6733",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5]) torch.Size([2, 5, 5])\n",
      "torch.Size([3, 1, 1])\n",
      "tensor([[[0.2126]],\n",
      "\n",
      "        [[0.7152]],\n",
      "\n",
      "        [[0.0722]]])\n",
      "torch.Size([3, 5, 5]) torch.Size([2, 3, 5, 5])\n",
      "torch.Size([5, 5]) torch.Size([2, 5, 5])\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.667486Z",
     "start_time": "2025-09-09T09:34:18.648545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#give your tensor index a name?\n",
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "print(weights_named)\n",
    "img_named =  img_t.refine_names(..., 'channels', 'rows', 'columns') #对dimension 进行重命名\n",
    "batch_named = batched_img_t.refine_names(..., 'channels', 'rows', 'columns') #这里的... 相当于list中的 :\n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ],
   "id": "3669136e162c708c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2126, 0.7152, 0.0722], names=('channels',))\n",
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.683433Z",
     "start_time": "2025-09-09T09:34:18.676452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#对 拥有维度命名的 Tensor 进行自动维度扩增 将 align as b\n",
    "# 该过程也被称为广播机制\n",
    "'''Requirements:\n",
    "All dimensions of the input tensor (self) must be named.\n",
    "All dimension names of self must exist in other.names. However, other can have additional dimension names not present in self, for which size-one dimensions are added in the output\n",
    "'''\n",
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned.shape, weights_aligned.names\n",
    "\n",
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names\n"
   ],
   "id": "db0b8f463fbce226",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.886788Z",
     "start_time": "2025-09-09T09:34:18.694393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(img_named[..., :3])\n",
    "print(weights_named)\n",
    "##当使用 基于维度名称的 方法调用时，两个tensor调用维度右边的维度结构和对应名称需要一致\n",
    "gray_named = (img_named[..., :3] * weights_named).sum('channels')"
   ],
   "id": "394a831427e4c713",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0910,  0.8224, -0.1598],\n",
      "         [-0.9540,  0.4426,  0.2627],\n",
      "         [ 0.2740, -0.2844,  0.6031],\n",
      "         [-0.1608,  1.5730, -0.4043],\n",
      "         [ 0.1560, -0.5832,  0.0192]],\n",
      "\n",
      "        [[-2.0772,  1.2196,  2.5565],\n",
      "         [ 1.3061, -0.9751, -0.3076],\n",
      "         [ 0.2361, -0.5522, -0.6863],\n",
      "         [-0.7045,  0.5349,  1.9416],\n",
      "         [ 0.0611,  0.2697,  1.1704]],\n",
      "\n",
      "        [[-0.6427, -0.1154, -0.2301],\n",
      "         [ 0.1354,  1.7750, -0.1301],\n",
      "         [ 0.9476,  0.3809, -0.5073],\n",
      "         [-0.2495, -1.5202, -0.3195],\n",
      "         [-0.9610, -0.6555, -1.8018]]], names=('channels', 'rows', 'columns'))\n",
      "tensor([0.2126, 0.7152, 0.0722], names=('channels',))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[60], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(weights_named)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m##当使用 基于维度名称的 方法调用时，两个tensor调用维度右边的维度结构和对应名称需要一致\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m gray_named \u001B[38;5;241m=\u001B[39m (\u001B[43mimg_named\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mweights_named\u001B[49m)\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchannels\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match."
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.896755100Z",
     "start_time": "2025-08-16T05:26:46.695483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 由于这玩意到底是个实验功能，最后还是让我们回到 未命名的tensor域\n",
    "gray_plain = gray_named.rename(None) #使用 remane(None)来消除原始命名\n",
    "gray_plain.shape, gray_plain.names"
   ],
   "id": "6abddd382ff980f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), (None, None))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:18.896755100Z",
     "start_time": "2025-08-16T05:39:27.341670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# customize your dtype in the tensor\n",
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)\n",
    "print(double_points.dtype)\n",
    "print(short_points.dtype)\n",
    "double_points = torch.ones(10,2).double()\n",
    "short_points=torch.tensor([[1,3],[2,4]]).short()\n",
    "print(double_points.dtype)\n",
    "print(short_points.dtype)\n",
    "double_points=torch.ones(10,2).to(torch.double)\n",
    "short_points=torch.tensor([[1,3],[2,4]]).to(torch.short)\n",
    "print(double_points.dtype)\n",
    "print(short_points.dtype)\n"
   ],
   "id": "9366b77d39f945d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int16\n",
      "torch.float64\n",
      "torch.int16\n",
      "torch.float64\n",
      "torch.int16\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 张量转置/切换维度次序\n",
    "\n",
    "x = torch.randn(2, 3, 4, 5)  # shaz, 3, 4, 5]\n",
    "y = x.transpose(1, 2)   # 交换 dim1 和 dim2  #transpose适合两个维度进行交换\n",
    "print(y.shape)  # 输出: [2, 4, 3, 5]\n",
    "\n",
    "x = torch.randn(2, 3) #偷懒模式下可以使用 t()来进行转置， 但这一函数只能用在维度小于等于2的情况\n",
    "y = x.t()\n",
    "print(y.shape)\n",
    "\n",
    "x = torch.randn(2, 3, 4, 5)  # shape: [2, 3, 4, 5]\n",
    "y = x.permute(0, 2, 1, 3)    # 调整维度顺序为 [0, 2, 1, 3] permute适合同时多个维度调整\n",
    "print(y.shape)  # 输出: [2, 4, 3, 5]\n",
    "\n",
    "x = torch.randn(2, 3, 4, 5)  # shape: [2, 3, 4, 5]\n",
    "y = x.mT                     # 转置最后两个维度，这个操作的逻辑多见于图像处理\n",
    "print(y.shape)  # 输出: [2, 3, 5, 4]\n"
   ],
   "id": "c9299fc85513906a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#张量基本计算操作\n",
    "\n",
    "x=torch.randn(2,2,2)\n",
    "print(x)\n",
    "#以下操作都是可以选定要执行操作的具体dim的\n",
    "#1.point wise(element wise)\n",
    "print(\"-----point wise----\")\n",
    "y=x.abs()\n",
    "print(y)\n",
    "y=x.cos()\n",
    "print(y)\n",
    "\n",
    "#2.reduction ops\n",
    "print(\"----reduction----\")\n",
    "y=x.mean()\n",
    "print(y)\n",
    "y=x.std()\n",
    "print(y)\n",
    "y=x.norm()\n",
    "print(y)\n",
    "\n",
    "#3.comparison ops\n",
    "print(\"----comparison----\")\n",
    "z=torch.randn(2,2,2)\n",
    "print(x.max())\n",
    "print(x.equal(z))\n",
    "\n"
   ],
   "id": "b14ec66258198605"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## contiguous tensor\n",
    "## 当tensor的存储(storge)格式恰好是其要表示的tensor从左到右的元素排列（2D下逐行从左到右写在storge中)时 该Tensor是contiguous的\n",
    "## torch的很多功能仅限于contiguous tensor\n",
    "\n",
    "a=torch.randn(2,2,2)\n",
    "print(a.is_contiguous())\n",
    "print(a.storage())\n",
    "print(a.stride())\n",
    "#转置不会更改storge中等的元素存储 但会改变stride信息\n",
    "b=a.transpose(1,2)\n",
    "print(b.is_contiguous())\n",
    "print(b.storage())\n",
    "print(b.stride())\n"
   ],
   "id": "8066e673199218ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:34:23.758095Z",
     "start_time": "2025-09-09T09:34:23.740314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "## hdf5 locking files turned down"
   ],
   "id": "491da3eb5735ebf6",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## serialize a tensor\n",
    "torch.save(a,\"temp_storge/temp_tensor.t\")\n",
    "points = torch.load('temp_storge/temp_tensor.t')\n",
    "print(points)\n",
    "\n",
    "## serialize a tensor with h5\n",
    "import h5py\n",
    "import os\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "\n",
    "with h5py.File(\"temp_storge/ourpoints.hdf5\", 'w') as f:\n",
    "    dset = f.create_dataset('test_point', data=points.numpy())\n",
    "    print(\"Dataset created successfully.\")\n",
    "\n",
    "f2 = h5py.File('temp_storge/ourpoints.hdf5', 'r')\n",
    "dset_load = f2['test_point']\n",
    "print(dset_load)\n",
    "f2.close()\n"
   ],
   "id": "bdab89afec06447c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:49:23.025328Z",
     "start_time": "2025-09-09T09:49:22.984956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## exercise after book I\n",
    "list_a=[i for i in range(9)]\n",
    "print(list_a)\n",
    "init_tesnor=torch.tensor(list_a,device=torch.device('cuda'))\n",
    "print(init_tesnor.dtype)\n",
    "print(init_tesnor.shape)\n",
    "print(init_tesnor.stride())\n",
    "\n",
    "b=init_tesnor.view(3,3)\n",
    "print(init_tesnor.storage())\n",
    "print(b.storage())\n",
    "print(b)\n",
    "\n",
    "c=b[1:,1:]\n",
    "print(c)"
   ],
   "id": "552fe9c7b512ba9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "torch.int64\n",
      "torch.Size([9])\n",
      "(1,)\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cuda:0) of size 9]\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      "[torch.storage.TypedStorage(dtype=torch.int64, device=cuda:0) of size 9]\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]], device='cuda:0')\n",
      "tensor([[4, 5],\n",
      "        [7, 8]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T09:54:05.993004Z",
     "start_time": "2025-09-09T09:54:05.963594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## exercise after book II\n",
    "import math\n",
    "b=init_tesnor.square()\n",
    "c=init_tesnor**(1/2)\n",
    "d=torch.sqrt(init_tesnor)\n",
    "# e=math.sqrt(init_tesnor) #You can't use scala method on tensors more than 1 dim\n",
    "print(d)"
   ],
   "id": "14b27b61564d1898",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[80], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m c\u001B[38;5;241m=\u001B[39minit_tesnor\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      5\u001B[0m d\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39msqrt(init_tesnor)\n\u001B[1;32m----> 6\u001B[0m e\u001B[38;5;241m=\u001B[39m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43minit_tesnor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(e)\n",
      "\u001B[1;31mValueError\u001B[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
